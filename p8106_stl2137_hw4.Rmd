---
title: "p8106_stl2137_hw4"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lasso2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(ModelMetrics)
```

# Question 1

```{r}
### Loading in prostate data
data("Prostate") 
dat_prostate <- Prostate
```

## Part A

```{r}
set.seed(1)

tree_prost_1 <- rpart(formula = lpsa ~., data = dat_prostate)
rpart.plot(tree_prost_1)

### Finding lowest cp 
cp_table <- printcp(tree_prost_1)
#plotcp(tree_prost_1)

minErr <- which.min(cp_table[,4])

# minimum cross-validation error
tree_prost_3 <- prune(tree_prost_1, cp = cp_table[minErr, 1])

# 1SE rule
tree_prost_4 <- prune(tree_prost_1, cp = 
                        cp_table[cp_table[,4] < cp_table[minErr, 4] + cp_table[minErr, 5], 1][1])

rpart.plot(tree_prost_3)
rpart.plot(tree_prost_4)
```

The tree size that corresponds to the lowest cross-validation error is 8. This is not the same tree size as the one obtained using the 1 SE rule, as the tree size is 3. 

## Part B

Pick one of the terminal nodes, and interpret the information displayed.

```{r}
plotcp(tree_prost_1)
```

Based off the leftmost value for which the mean lies below the horizontal line in the cp plot, a cp = 0.1 and a tree size of 3 should be utilized. 

```{r}
set.seed(1)

final_tree_prost <- rpart(lpsa ~ ., data = dat_prostate,
                          control = rpart.control(cp = 0.1))

rpart.plot(final_tree_prost)
```

## Part C

(c) report the variable importance.

```{r}
set.seed(1)

bagging_prost <- randomForest(lpsa ~ ., data = dat_prostate,
                              mtry = 8)

bagging_prost$importance
```

## Part D

(d) report the variable importance.

```{r}
set.seed(1)
rf_prost <- randomForest(lpsa ~ ., data = dat_prostate,
                         mtry = 3)

rf_prost$importance
```

## Part E

(e) report the variable importance.

```{r}
set.seed(1)
boosting_prost <- gbm(lpsa ~ ., data = dat_prostate,
                      distribution = "gaussian",
                      n.trees = 5000,
                      interaction.depth = 3,
                      shrinkage = 0.005,
                      cv.folds = 10)

nt <- gbm.perf(boosting_prost, method = "cv")
```

## Part F

(f) Which of the above models will you select to predict PSA level? Explain.

```{r}

```

# Problem 2

## Pulling & Creating Training/Test Datasets
```{r}
data("OJ")
dat_oj <- OJ %>% 
  janitor::clean_names()

set.seed(1)

rowTrain <- createDataPartition(y = dat_oj$purchase,
                               p = 799/1070,
                               list = FALSE)

train_dat_oj <- as.data.frame(dat_oj[rowTrain,])
test_dat_oj <- as.data.frame(dat_oj[-rowTrain,])

```

## Part A


```{r}
set.seed(1)

oj_tree <- rpart(purchase ~., data = dat_oj,
                 subset = rowTrain,
                 control = rpart.control(cp = 0))
#rpart.plot(oj_tree)

cp_table_oj <- printcp(oj_tree)
plotcp(oj_tree)
minErr_oj <- which.min(cp_table_oj[,4])

# minimum cross-validation error
oj_tree_2 <- prune(oj_tree, cp = cp_table_oj[minErr_oj, 1])
rpart.plot(oj_tree_2)

oj_tree_pred <- predict(oj_tree_2, newdata = test_dat_oj)
oj_tree_mse <- mse(oj_tree_pred, test_dat_oj$purchase)
```
Using cross-validation to determine the tree size, the tree size should be 6. The test classification MSE is `r oj_tree_mse`, so the classification error rate is `r 1- oj_tree_mse`.

## Part B

Perform random forests on the training set and report variable importance. What is the test error rate?

```{r}

```

